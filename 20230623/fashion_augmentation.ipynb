{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac27837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(trainX, trainY), (validX, validY) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "trainX[0]\n",
    "trainX.shape\n",
    "validX.shape\n",
    "# 정답 레이블, 사진의 종류 10가지\n",
    "trainY\n",
    "\n",
    "class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress','Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6266ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trainX = trainX / 255.0\n",
    "validX = validX / 255.0\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], trainX.shape[2], 1))\n",
    "validX = validX.reshape((validX.shape[0], validX.shape[1], validX.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418bf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43247b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.NumpyArrayIterator object at 0x0000013FA55A5490>\n"
     ]
    }
   ],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range = 10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range = 0.1, \n",
    "    height_shift_range = 0.1, \n",
    "    horizontal_flip = True, \n",
    "    vertical_flip = False,\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainD = datagen.flow(trainX, trainY, batch_size=batch_size)\n",
    "validD = datagen.flow(validX, validY, batch_size=batch_size)\n",
    "\n",
    "print(img_iter)\n",
    "datagen.fit(trainX)\n",
    "\n",
    "\n",
    "# gen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "#                          height_shift_range=shift_fraction,\n",
    "#                          horizontal_flip=True)\n",
    "# batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "# val_batches = gen.flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "# fashion_train=fashion_model.fit_generator(batches, steps_per_epoch=X_train.shape[0]//batch_size, \n",
    "#                                           epochs=epochs,validation_data=val_batches, \n",
    "#                                                    validation_steps=X_val.shape[0]//batch_size, use_multiprocessing=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eab3f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_16188\\2267164362.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(trainD, steps_per_epoch=len(trainX)//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 68s 35ms/step - loss: 0.5278 - accuracy: 0.8048 - val_loss: 0.5255 - val_accuracy: 0.8111\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.4722 - accuracy: 0.8239 - val_loss: 0.4718 - val_accuracy: 0.8255\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.4457 - accuracy: 0.8339 - val_loss: 0.4583 - val_accuracy: 0.8272\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.4226 - accuracy: 0.8430 - val_loss: 0.4557 - val_accuracy: 0.8274\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.4081 - accuracy: 0.8470 - val_loss: 0.4292 - val_accuracy: 0.8382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13fa54dd550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(trainX, trainY, validation_data=(validX, validY), epochs=5)\n",
    "model.fit_generator(trainD, steps_per_epoch=len(trainX)//batch_size, \n",
    "                    validation_data=(validD),validation_steps=validX.shape[0]//batch_size, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "982de660",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.datasets' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \ty \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(y, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     36\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[1;32m---> 38\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miris\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[:80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miris\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m:]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.datasets' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "#Category 2 - Iris 꽃 분류\n",
    "#\n",
    "#Fully Connected Layer (Dense)를 활용한 분류 모델 (Classification)\n",
    "#tensorflow-datasets 를 활용한 데이터 전처리\n",
    "\n",
    "#For this task you will train a classifier for Iris flowers using the Iris dataset\n",
    "#The final layer in your neural network should look like: tf.keras.layers.\n",
    "#Dense(3, activation=tf.nn.softmax)\n",
    "#The input layer will expect data in the shape (4,)\n",
    "#We've given you some starter code for preprocessing the data\n",
    "#You'll need to implement the preprocess function for data.map\n",
    "\n",
    "#이 작업에서는 Iris 데이터 세트를 사용하여 Iris 꽃 분류기를 훈련시킵니다.\n",
    "#신경망의 마지막 계층은 tf.keras.layers와 같아야합니다.\n",
    "#Dense(3, activation='softmax')\n",
    "#입력 레이어는 모양의 데이터를 기대합니다 (4,)\n",
    "#데이터 전처리를위한 스타터 코드를 제공했습니다\n",
    "#data.map에 대한 전처리 기능을 구현해야합니다.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as tfds\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "\t# 코드를 입력하세요\n",
    "\tx = data['features']\n",
    "\ty = data['label']\n",
    "\ty = tf.one_hot(y, 3)\n",
    "\treturn x, y\n",
    "\n",
    "train_dataset = tfds.load('iris', split='train[:80%]')\n",
    "valid_dataset = tfds.load('iris', split='train[80%:]')\n",
    "\n",
    "\n",
    "batch_size=10\n",
    "train_data = train_dataset.map(preprocess).batch(batch_size)\n",
    "valid_data = valid_dataset.map(preprocess).batch(batch_size)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\t# input_shape는 X의 feature 갯수가 4개 이므로 (4, )로 지정합니다.\n",
    "\tDense(512, activation='relu', input_shape=(4,)),\n",
    "\tDense(256, activation='relu'),\n",
    "\tDense(128, activation='relu'),\n",
    "\tDense(64, activation='relu'),\n",
    "\tDense(32, activation='relu'),\n",
    "\t# Classification을 위한 Softmax, 클래스 갯수 = 3개\n",
    "\tDense(3, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "checkpoint_path = \"my_checkpoint.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "\tsave_weights_only=True, \n",
    "\tave_best_only=True, \n",
    "\tmonitor='val_loss', \n",
    "\terbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(train_data,\n",
    "\tvalidation_data=(valid_data),\n",
    "\tepochs=20,\n",
    "\tcallbacks=[checkpoint], \n",
    ")\n",
    "\n",
    "\n",
    "# checkpoint 를 저장한 파일명을 입력합니다.\n",
    "model.load_weights(checkpoint_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "im_000000",
   "language": "python",
   "name": "im_000000"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
